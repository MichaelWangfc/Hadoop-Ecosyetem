{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS \n",
    "Hadoop distribute file system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### DataNode and  NameNode (active & standby)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoop fs -ls\n",
    "hadoop fs -mkdir myiput\n",
    "\n",
    "### Input the data \n",
    "hadoop fs -put purchases.txt myinput\n",
    "hadoop fs -ls myinput\n",
    "\n",
    "ls # to display the mapper.py ,reducer.py on my local home directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "to submit the job we have to give this rather cumbersome command. We say hadoop jar,a path to a jar, \n",
    "then I specify the mapper, I specify the reducer, I need to say file,for both the mapper and the reducer code. \n",
    "I specify the input directory in HDFS and I specify the output directory to which the reducers will write their output data\n",
    "'''\n",
    "hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.60-mr1-cdh4.1.1.jar -mapper mapper.py -reducer reducer.py\\\n",
    "-file mapper.py -file reducer.py -input myinput -output joboutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### check the result\n",
    "hadoop fs -ls\n",
    "hadoop fs -ls joboutput\n",
    "hadoop fs -cat joboutput/part-0000 | less\n",
    "hadoop fs -get joboutput/part-0000 mylocalfile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNNING A MAPREDUCE JOB WITH THE VM ALIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs {mapper script} {reducer script} {input_file} {output directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs mapper.py reducer.py myinput joboutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDFS operation\n",
    "#### give the list of hadoop file systm home directory\n",
    "hadoop fs -ls\n",
    "\n",
    "#### upload a file to a hdfs\n",
    "hadoop fs -put purchases.txt\n",
    "\n",
    "#### display the last few line\n",
    "hadoop fs -tail purchases.txt\n",
    "\n",
    "#### display the entire content of file\n",
    "hadoop fs -cat purchases.txt\n",
    "\n",
    "#### rename the file \n",
    "hadoop fs -mv purchases.txt newname.txt\n",
    "\n",
    "#### delete the file\n",
    "hadoop fs -rm newname.txt\n",
    "\n",
    "#### make a directory\n",
    "hadoop fs -mkdir myinput\n",
    "\n",
    "#### upload a file into a directory on hdfs\n",
    "hadoop fs -put purchases.txt myinput\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MapReduce\n",
    "### Mapper and Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### java and pathon \n",
    "### hadoop stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defensive Mapper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your task is to make sure that this mapper code does not fail on corrupt data lines,\n",
    "# but instead just ignores them and continues working\n",
    "import sys\n",
    "\n",
    "def mapper():\n",
    "    # read standard input line by line\n",
    "    for line in sys.stdin:\n",
    "        # strip off extra whitespace, split on tab and put the data in an array\n",
    "        data = line.strip().split(\"\\t\")\n",
    "\n",
    "        # This is the place you need to do some defensive programming\n",
    "        # what if there are not exactly 6 fields in that line?\n",
    "        # YOUR CODE HERE\n",
    "        if len(data) == 6:\n",
    "            # this next line is called 'multiple assignment' in Python\n",
    "            # this is not really necessary, we could access the data\n",
    "            # with data[2] and data[5], but we do this for conveniency\n",
    "            # and to make the code easier to read\n",
    "            date, time, store, item, cost, payment = data\n",
    "            \n",
    "            # Now print out the data that will be passed to the reducer\n",
    "            print \"{0}\\t{1}\".format(store, cost)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "test_text = \"\"\"2013-10-09\\t13:22\\tMiami\\tBoots\\t99.95\\tVisa\n",
    "2013-10-09\\t13:22\\tNew York\\tDVD\\t9.50\\tMasterCard\n",
    "2013-10-09 13:22:59 I/O Error\n",
    "^d8x28orz28zoijzu1z1zp1OHH3du3ixwcz114<f\n",
    "1\\t2\\t3\"\"\"\n",
    "\n",
    "# This function allows you to test the mapper with the provided test string\n",
    "def main():\n",
    "\timport StringIO\n",
    "\tsys.stdin = StringIO.StringIO(test_text)\n",
    "\tmapper()\n",
    "\tsys.stdin = sys.__stdin__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffeld and sort by key into Hadoop stream\n",
    "## Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "salesTotal = 0\n",
    "oldKey = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    data = line.strip().split(\"\\t\")\n",
    "    if len(data) != 2:\n",
    "        # Something has gone wrong. Skip this line.\n",
    "        continue\n",
    "\n",
    "    thisKey, thisSale = data\n",
    "    if oldKey and oldKey != thisKey:\n",
    "        print oldKey, \"\\t\", salesTotal\n",
    "        oldKey = thisKey\n",
    "        salesTotal = 0\n",
    "\n",
    "    oldKey = thisKey\n",
    "    salesTotal += float(thisSale)\n",
    "\n",
    "if oldKey != None:\n",
    "    print oldKey, \"\\t\", salesTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job tracker and task tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for the mapper.py and reducer.py on the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls ../data\n",
    "head -50 ../data/purchases.txt >testfile\n",
    "cat testfile | ./mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat testfile | ./mapper.py | sort | ./reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the job on clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs mapper.py reducer.py myinput joboutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### watch the procssing from the web\n",
    "job tracker web user interface\n",
    "localhost:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application for MapReduce\n",
    "#### recommendation system\n",
    "#### fraud detection\n",
    "#### item classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Mapper and reducer :project1\n",
    "import sys\n",
    "\n",
    "def mapper():\n",
    "    # read standard input line by line\n",
    "    for line in sys.stdin:\n",
    "        # strip off extra whitespace, split on tab and put the data in an array\n",
    "        data = line.strip().split(\"\\t\")\n",
    "\n",
    "        # This is the place you need to do some defensive programming\n",
    "        # what if there are not exactly 6 fields in that line?\n",
    "        # YOUR CODE HERE\n",
    "        if len(data) == 6:\n",
    "            # this next line is called 'multiple assignment' in Python\n",
    "            # this is not really necessary, we could access the data\n",
    "            # with data[2] and data[5], but we do this for conveniency\n",
    "            # and to make the code easier to read\n",
    "            date, time, store, item, cost, payment = data\n",
    "            \n",
    "            # Now print out the data that will be passed to the reducer\n",
    "            print \"{0}\\t{1}\".format(item, cost)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "test_text = \"\"\"2013-10-09\\t13:22\\tMiami\\tBoots\\t99.95\\tVisa\n",
    "2013-10-09\\t13:22\\tNew York\\tDVD\\t9.50\\tMasterCard\n",
    "2013-10-09 13:22:59 I/O Error\n",
    "^d8x28orz28zoijzu1z1zp1OHH3du3ixwcz114<f\n",
    "1\\t2\\t3\"\"\"\n",
    "\n",
    "# This function allows you to test the mapper with the provided test string\n",
    "def main():\n",
    "\timport StringIO\n",
    "\tsys.stdin = StringIO.StringIO(test_text)\n",
    "\tmapper()\n",
    "\tsys.stdin = sys.__stdin__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
